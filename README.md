# ğŸ¤Ÿ Sign Language Translator

The **Sign Language Translator** is a Python-based deep learning project that interprets American Sign Language (ASL) hand gestures using a webcam and translates them into English alphabets. It uses **OpenCV**, **MediaPipe**, and **TensorFlow/Keras** to detect and recognize hand signs in real-time, helping bridge the communication gap for the deaf and hard-of-hearing community.

---

## ğŸ“Œ Features

- ğŸ¥ Real-time ASL gesture recognition using webcam
- ğŸ§  Convolutional Neural Network (CNN) for classification
- âœ‹ Hand detection powered by MediaPipe
- ğŸ’¾ Easy-to-use dataset collection tool
- ğŸ–¥ Visual prediction display using OpenCV

---

## ğŸ›  Tech Stack

- **Python 3.x**
- **TensorFlow / Keras**
- **OpenCV**
- **MediaPipe**
- **NumPy**
- **Matplotlib**

---

## ğŸ“ Project Structure
sign-language-translator/
â”‚
â”œâ”€â”€ dataset/ # Folder containing gesture images A-Z
â”‚ â”œâ”€â”€ A/, B/, C/, ... # Subfolders for each alphabet
â”‚
â”œâ”€â”€ model/ # Trained model
â”‚ â””â”€â”€ asl_model.h5
â”‚
â”œâ”€â”€ collect_dataset.py # Script to collect hand gesture images
â”œâ”€â”€ train_model.py # Script to train the CNN model
â”œâ”€â”€ predict.py # Script for real-time predictions
â”œâ”€â”€ requirements.txt # List of Python dependencies
â”œâ”€â”€ README.md # Project documentation

## ğŸš€ How to Run the Project

### 1. Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/sign-language-translator.git
cd sign-language-translator

2. Create a Virtual Environment (Optional)
python -m venv venv
# Activate the virtual environment
venv\Scripts\activate      # On Windows
source venv/bin/activate   # On Linux/macOS

3. Install Dependencies
pip install -r requirements.txt
## If requirements.txt is not available, manually install:
pip install opencv-python mediapipe tensorflow numpy matplotlib

ğŸ“¸ Collect the Dataset
Capture images for each ASL alphabet (A-Z) using your webcam:
python collect_dataset.py

ğŸ§  Train the Model
Once the dataset is collected, run:
-> python train_model.py
This will train a CNN and save the model as model/asl_model.h5

ğŸ¤– Run Real-Time Prediction
To run the live sign language translator using webcam:
python predict.py

ğŸ–¼ Sample Output
âœ‹ Detected â†’ B
ğŸ¤™ Detected â†’ Y
ğŸ‘Œ Detected â†’ F

ğŸ’¡ Future Enhancements
ğŸ”  Full sentence recognition
ğŸ“š Add support for dynamic gestures and words
ğŸŒ Multi-language translation support
ğŸ§© GUI-based interface using Tkinter or PyQt
